{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28268d29-8799-452c-870d-3412d39ad703",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda0006-0a3b-42f3-b959-5a53b4be5829",
   "metadata": {},
   "source": [
    "First let's import the libraries that we are going to use for this tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2c023b5-21d0-42b5-b7a4-f36cf233905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d632e8c5-d866-4384-9de4-3e65d242ca02",
   "metadata": {},
   "source": [
    "Next, we define the path location for our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da2f5e7d-e4b0-45f5-8f08-0fd9dc94d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../data/raw/may/images\"   \n",
    "label_dir = \"../data/raw/may/labels\"   \n",
    "os.makedirs(label_dir, exist_ok = True)\n",
    "os.makedirs(image_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6b83f-05d6-440c-bbb7-6a59fe604b26",
   "metadata": {},
   "source": [
    "### Pre-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e9a1c-4986-4d92-9743-f6852ee8e1e0",
   "metadata": {},
   "source": [
    "We want the images and the labels to have standard naming format such that the name tells you the period and the image type.\n",
    "\n",
    "For example; \"may_afternoon_0_lwir_89.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140a81e-9c97-4c84-b891-d96989f7731d",
   "metadata": {},
   "source": [
    "First rename the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c790498-f47f-4693-bf85-e5ab05265529",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"may_afternoon_\"\n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "\n",
    "    if filename.endswith(\".jpg\") and not filename.startswith(prefix):\n",
    "        \n",
    "        old_path = os.path.join(image_dir, filename)\n",
    "        new_filename = prefix + filename\n",
    "        new_path = os.path.join(image_dir, new_filename)\n",
    "\n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaccf15-7839-442a-b103-974bfbce678b",
   "metadata": {},
   "source": [
    "Next rename the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ad2ed4-e762-49bd-93e9-0568a14d4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(label_dir):\n",
    "\n",
    "    if filename.endswith(\".xml\") and not filename.startswith(prefix):\n",
    "        \n",
    "        old_path = os.path.join(label_dir, filename)\n",
    "        new_filename = prefix + filename\n",
    "        new_path = os.path.join(label_dir, new_filename)\n",
    "\n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32add5a-d7d0-4d28-b5f6-ecdbd1098b71",
   "metadata": {},
   "source": [
    "Each of the objects in the images are labelled as either *'ap_metal', 'ap_plastic', 'at_metal'* or , *'at_plastic'*. Let us write a code that iterates through all the labels and extract these unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b089356a-cb75-49b5-9fc9-4e257fc3c7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes found: ['ap_metal', 'ap_plastic', 'at_metal', 'at_plastic']\n"
     ]
    }
   ],
   "source": [
    "unique_classes = set()\n",
    "\n",
    "for filename in os.listdir(label_dir):\n",
    "    \n",
    "    if filename.endswith(\".xml\"):\n",
    "        \n",
    "        filepath = os.path.join(label_dir, filename)\n",
    "        tree = ET.parse(filepath)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Iterate over each object tag\n",
    "        for obj in root.findall(\"object\"):\n",
    "            \n",
    "            class_name = obj.find(\"name\").text\n",
    "            unique_classes.add(class_name)\n",
    "\n",
    "# Convert to a sorted list\n",
    "class_list = sorted(list(unique_classes))\n",
    "\n",
    "print(\"Unique classes found:\", class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c1ede-07ff-4c9f-a2af-a3b7b81aeaeb",
   "metadata": {},
   "source": [
    "Next, we need to convert the labels into a format that is acceptable by YOLO. We achieve this by writing a function that accepts the \".xml\" annotation file, it extracts the image width and height, loops over each label to find the image class, check if its known against the class list from the previous code and then convert the class names into unique index as YOLO only recognizes IDs and not names.\n",
    "\n",
    "The function then extracts bounding box coordinates from the .xml file before converting it to YOLO format by normalizing them from 0 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72b1fa48-9a88-4a98-8eb0-4cc7a9a51ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_voc_to_yolo(xml_file):\n",
    "    \"\"\"\n",
    "    This function reads .xml annotation file, \n",
    "    extracts bounding boxes and class names \n",
    "    before converting them to YOLO format of \n",
    "    one string per object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xml_file : string\n",
    "        The path to a Pascal VOC-style XML \n",
    "        annotation label file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    w = int(root.find(\"size/width\").text)\n",
    "    h = int(root.find(\"size/height\").text)\n",
    "    \n",
    "    yolo_lines = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        \n",
    "        cls = obj.find(\"name\").text\n",
    "        if cls not in class_list:\n",
    "            \n",
    "            continue\n",
    "        cls_id = class_list.index(cls)\n",
    "        xmlbox = obj.find(\"bndbox\")\n",
    "        xmin = int(xmlbox.find(\"xmin\").text)\n",
    "        ymin = int(xmlbox.find(\"ymin\").text)\n",
    "        xmax = int(xmlbox.find(\"xmax\").text)\n",
    "        ymax = int(xmlbox.find(\"ymax\").text)\n",
    "\n",
    "        # Convert to YOLO format\n",
    "        x_center = ((xmin + xmax) / 2) / w\n",
    "        y_center = ((ymin + ymax) / 2) / h\n",
    "        bw = (xmax - xmin) / w\n",
    "        bh = (ymax - ymin) / h\n",
    "        yolo_lines.append(f\"{cls_id} {x_center} {y_center} {bw} {bh}\")\n",
    "        \n",
    "    return yolo_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ab09f-e5b5-4762-8ce0-87ec40a1e239",
   "metadata": {},
   "source": [
    "We loop over the .xml files in label folder, convert the annotations from VOC format to YOLO using the our function and then save them as text files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a165099-0d7b-4d00-93dc-7c5a06dba934",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"../data/raw/may/text\" \n",
    "os.makedirs(text_dir, exist_ok = True)\n",
    "\n",
    "for xml_file in os.listdir(label_dir):\n",
    "    \n",
    "    if not xml_file.endswith(\".xml\"):\n",
    "        \n",
    "        continue\n",
    "        \n",
    "    xml_path = os.path.join(label_dir, xml_file)\n",
    "    txt_path = os.path.join(text_dir, xml_file.replace(\".xml\", \".txt\"))\n",
    "    \n",
    "    yolo_data = convert_voc_to_yolo(xml_path)\n",
    "    with open(txt_path, \"w\") as f:\n",
    "        \n",
    "        f.write(\"\\n\".join(yolo_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae3c9701-1ac1-4c4f-8b91-d6e64110dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base = \"../results/may/dataset\"\n",
    "train_ratio, val_ratio, test_ratio = 0.7, 0.2, 0.1\n",
    "\n",
    "#Shuffle the original images\n",
    "images = [f for f in os.listdir(image_dir) if f.endswith((\".jpg\", \".png\"))]\n",
    "random.shuffle(images)\n",
    "\n",
    "# Compute split indices\n",
    "total = len(images)\n",
    "train_end = int(total * train_ratio)\n",
    "val_end = train_end + int(total * val_ratio)\n",
    "\n",
    "# Split image filenames\n",
    "split_data = {\"train\": images[:train_end], \"val\": images[train_end:val_end],\n",
    "    \"test\": images[val_end:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb05014-e6cf-47b1-a52b-734bffb17cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder structure and copy files\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_out_dir = os.path.join(output_base, \"images\", split)\n",
    "    lbl_out_dir = os.path.join(output_base, \"labels\", split)\n",
    "    os.makedirs(img_out_dir, exist_ok=True)\n",
    "    os.makedirs(lbl_out_dir, exist_ok=True)\n",
    "\n",
    "    for img_file in split_data[split]:\n",
    "        # Copy image\n",
    "        shutil.copy(os.path.join(image_dir, img_file), os.path.join(img_out_dir, img_file))\n",
    "\n",
    "        # Copy corresponding label\n",
    "        txt_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        src_lbl = os.path.join(label_dir, txt_file)\n",
    "        if os.path.exists(src_lbl):\n",
    "            shutil.copy(src_lbl, os.path.join(lbl_out_dir, txt_file))\n",
    "        else:\n",
    "            pass #print(f\"⚠️ Label not found for image: {img_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e64e272-da8c-4493-a2f9-bebe04f221f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data.yaml created!\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"path\":output_base, \n",
    "    \"train\": os.path.join(\"../results/may/dataset/images/train\"),\n",
    "    \"val\": os.path.join(\"../results/may/dataset/images/val\"),\n",
    "    \"test\": os.path.join(\"../results/may/dataset/images/test\"),\n",
    "    \"nc\": len(class_list),\n",
    "    \"names\": class_list,\n",
    "}\n",
    "\n",
    "yaml_path = os.path.join(output_base, \"data.yaml\")\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    \n",
    "    yaml.dump(data, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aab0434b-8045-460a-920e-2bd74b5866f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2/6.2MB 3.1MB/s 2.0s0s\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42c17796-ef10-4a77-bf7a-c8623cb0d77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'images', 'labels', 'data.yaml']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(output_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2126ed47-9bd4-4d4a-8c43-e905d72feb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/may/dataset/data.yaml\n"
     ]
    }
   ],
   "source": [
    "yaml_file = os.path.join(output_base, \"data.yaml\")\n",
    "print(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e11e20-02f6-43b2-b6fc-18cfa91c11c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.186 🚀 Python-3.11.11 torch-2.8.0 CPU (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../results/may/dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 187.6±115.0 MB/s, size: 166.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/bosoro/Documents/GitHub/flight/results/may/dataset/labels/train... 0 images, 193 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 193/193 554.6it/s 0.3s\n",
      "WARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in /Users/bosoro/Documents/GitHub/flight/results/may/dataset/labels/train.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/bosoro/Documents/GitHub/flight/results/may/dataset/labels/train.cache\n",
      "WARNING ⚠️ Labels are missing or empty in /Users/bosoro/Documents/GitHub/flight/results/may/dataset/labels/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 176.2±132.2 MB/s, size: 155.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bosoro/Documents/GitHub/flight/results/may/dataset/labels/val... 0 images, 55 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 55/55 4255.3it/s 0.0s\n",
      "WARNING ⚠️ \u001b[34m\u001b[1mval: \u001b[0mNo labels found in /Users/bosoro/Documents/GitHub/flight/results/may/dataset/labels/val.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/bosoro/Documents/GitHub/flight/results/may/dataset/labels/val.cache\n",
      "WARNING ⚠️ Labels are missing or empty in /Users/bosoro/Documents/GitHub/flight/results/may/dataset/labels/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "Plotting labels to runs/detect/train3/labels.jpg... \n",
      "WARNING ⚠️ zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G          0      113.4          0          0        640: 100% ━━━━━━━━━━━━ 13/13 0.19it/s 1:08\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.22it/s 9.1s\n",
      "                   all         55          0          0          0          0          0\n",
      "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/50         0G          0      105.2          0          0        640: 100% ━━━━━━━━━━━━ 13/13 0.20it/s 1:05s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.30it/s 6.6s\n",
      "                   all         55          0          0          0          0          0\n",
      "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/50         0G          0      96.14          0          0        640: 100% ━━━━━━━━━━━━ 13/13 0.21it/s 1:03s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.30it/s 6.6s\n",
      "                   all         55          0          0          0          0          0\n",
      "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/50         0G          0      89.84          0          0        640: 100% ━━━━━━━━━━━━ 13/13 0.21it/s 1:02s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.31it/s 6.5s\n",
      "                   all         55          0          0          0          0          0\n",
      "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/50         0G          0      84.56          0          0        640: 100% ━━━━━━━━━━━━ 13/13 0.21it/s 1:02s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.31it/s 6.5s\n",
      "                   all         55          0          0          0          0          0\n",
      "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/50         0G          0      80.36          0          0        640: 100% ━━━━━━━━━━━━ 13/13 0.21it/s 1:02s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.30it/s 6.6s\n",
      "                   all         55          0          0          0          0          0\n",
      "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/50         0G          0      76.43          0          0        640: 100% ━━━━━━━━━━━━ 13/13 0.21it/s 1:03s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.31it/s 6.5s\n",
      "                   all         55          0          0          0          0          0\n",
      "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "/Users/bosoro/anaconda3/envs/deepimage/lib/python3.11/site-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/50         0G          0      79.43          0          0        640:  23% ━━╸───────── 3/13 0.12it/s 21.1s"
     ]
    }
   ],
   "source": [
    "model.train(data = yaml_path, epochs=50, imgsz=640, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59ef43-aab1-4012-823c-c464d8be88b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5896bcb7-82eb-403b-993b-912afb89c01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
